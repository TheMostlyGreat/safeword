---
description: BDD orchestrator for feature-level work requiring multiple scenarios. Use when user says 'add', 'implement', 'build', 'feature', 'iteration', 'phase', or work touches 3+ files with new state/flows. Also use when user runs /bdd. Do NOT use for bug fixes, typos, config changes, or 1-2 file tasks.
alwaysApply: false
---

# BDD Orchestrator

Behavior-first development for features. Discovery → Scenarios → Implementation.

**Iron Law:** DEFINE BEHAVIOR BEFORE IMPLEMENTATION

## Phase Tracking

Features progress through phases. Track in ticket frontmatter:

```yaml
---
type: feature
phase: implement # intake | define-behavior | scenario-gate | decomposition | implement | done
---
```

**Phase meanings:**

| Phase             | What happens                         |
| ----------------- | ------------------------------------ |
| `intake`          | Context check, discovery (Phase 0-2) |
| `define-behavior` | Writing Given/When/Then (Phase 3)    |
| `scenario-gate`   | Validating scenarios (Phase 4)       |
| `decomposition`   | Task breakdown (Phase 5)             |
| `implement`       | Outside-in TDD (Phase 6)             |
| `done`            | Cleanup, verification (Phase 7)      |

**Update phase when:**

- Completing a BDD phase → set next phase
- Handing off to TDD → set `implement`
- All scenarios pass → set `done`

---

## Resume Logic

When user references a ticket, resume work:

1. **Read ticket** → get current `phase:`
2. **Find progress** → first unchecked `[ ]` in test-definitions
3. **Check context** → read last work log entry
4. **Announce resume** → "Resuming at [phase]. Last: [log entry]."

**Resume by phase:**

| Phase             | Resume action                          |
| ----------------- | -------------------------------------- |
| `intake`          | Start context check (Phase 0-2)        |
| `define-behavior` | Continue drafting scenarios            |
| `scenario-gate`   | Continue validating scenarios          |
| `decomposition`   | Continue task breakdown                |
| `implement`       | Find first unchecked scenario, run TDD |
| `done`            | Run /verify and /audit checks          |

---

## Phase 0-2: Context Check & Discovery

**Entry:** Agent detects feature-level work OR resumes ticket at `intake` phase.

### Context Check

Check if spec exists with required context:

1. **Read spec** (or note if missing)
2. **Check for goal AND scope sections**
3. **If missing or incomplete** → ask context questions:
   - "What's the goal? What should users be able to do?"
   - "What's in scope? What are we building?"
   - "What's explicitly out of scope?"
4. **Create/update spec** with answers

**Exit context check:** Spec has goal AND scope sections.

**Edge case:** User gives partial answer (goal but not scope) → Ask only for missing field, don't re-ask answered questions.

### Discovery (Optional)

After context check, offer discovery:

> "Want to spitball edge cases before we dive in?"

**If user declines** (or says "ready") → update ticket to `define-behavior`, proceed to Phase 3.

**If user accepts** → run discovery rounds:

1. Ask 2-3 PM-style questions per round (see AGENTS.md "PM-Style Questions"):
   - Round 1: User experience ("What does success feel like?")
   - Round 2: Failure modes ("What breaks? What are consequences?")
   - Round 3: Boundaries ("What's the minimum? Maximum?")
   - Round 4: Scenarios ("Walk through a concrete situation")
   - Round 5: Regret ("If we skip this, what support tickets come?")
2. Capture insights in spec under "## Discovery" section
3. After each round: "Another round or ready to proceed?"
4. **Max 5 rounds** — after round 5, proceed automatically

**Exit discovery:** User says "ready" OR max rounds reached → update ticket to `define-behavior`.

**Example round:**

> Agent: "Round 2 - Failure modes. What happens when a session expires mid-flow? What's the worst-case scenario?"
> User: "They lose progress. We'd get support tickets about lost work."
> Agent: "Got it - session expiry = data loss risk. Another round or ready?"

---

## Phase 3: Define Behavior

**Entry:** Agent enters `define-behavior` phase (after discovery or resume)

**Draft scenarios:**

1. Read spec goal/scope
2. Draft Given/When/Then scenarios covering:
   - Happy path (main success)
   - Failure modes (what can go wrong)
   - Edge cases (boundaries, empty states)
3. Present scenarios to user
4. User can add/modify/remove scenarios
5. Save to `.safeword-project/test-definitions/feature-{slug}.md`
6. Each scenario gets `[ ]` checkbox for implementation tracking

**Exit:** User approves scenario list → update ticket to `phase: scenario-gate`

---

## Phase 4: Scenario Quality Gate

**Entry:** Agent enters `scenario-gate` phase

**Validate each scenario against three criteria:**

| Criterion         | Check                          | Red flag                        |
| ----------------- | ------------------------------ | ------------------------------- |
| **Atomic**        | Tests ONE behavior             | Multiple When/Then pairs        |
| **Observable**    | Has externally visible outcome | Internal state only             |
| **Deterministic** | Same result on repeated runs   | Time/random/external dependency |

**Report issues:**

- Group by type (atomicity, observability, determinism)
- Suggest fix for each issue
- Example: "Scenario 3 tests login AND session creation. Split into two scenarios."

**Exit options:**

- All pass → update ticket to `decomposition`
- Issues found → user fixes or acknowledges → update ticket to `decomposition`

---

## Phase 5: Technical Decomposition

**Entry:** Agent enters `decomposition` phase (after scenarios validated)

**Analyze scenarios for implementation:**

1. **Identify components** — What parts of the system does each scenario touch?
   - UI components
   - API endpoints
   - Data models
   - Business logic modules
2. **Assign test layers** — For each component:
   - Pure logic (no I/O) → unit test
   - API boundaries, database → integration test
   - User flows → E2E test
3. **Create task breakdown** — Order by dependencies:
   - Data models first
   - Business logic second
   - API endpoints third
   - UI components fourth
   - E2E tests last (prove everything works)
4. **Present to user** — Show components, test layers, task order

**Complex features** (3+ components, new tech choices, schema changes) may warrant documentation first. See `.safeword/guides/design-doc-guide.md` for feature-level decisions, `.safeword/guides/architecture-guide.md` for cross-cutting choices.

**Exit:** User approves breakdown → update ticket to `phase: implement`

---

## Phase 6: Implementation (TDD)

**Entry:** Agent enters `implement` phase (after decomposition complete)

**Iron Law:** NO IMPLEMENTATION UNTIL TEST FAILS FOR THE RIGHT REASON

Announce: "Entering implementation. TDD mode for each scenario."

### Walking Skeleton (first scenario only)

If project has no E2E infrastructure, build skeleton first:

- Thinnest possible slice proving architecture works
- Form → API → response → UI (no real logic)
- This becomes foundation for all scenarios

### For Each Scenario (RED → GREEN → REFACTOR):

#### 6.1 RED - Write Failing Test

1. Pick ONE test from test-definitions (first unchecked `[ ]`)
2. Write E2E test code (from Given/When/Then)
3. Run test → verify fails for RIGHT reason (behavior missing, not syntax)
4. Commit: `test: [scenario name]`

**Red Flags → STOP:**

| Flag                    | Action                           |
| ----------------------- | -------------------------------- |
| Test passes immediately | Rewrite - you're testing nothing |
| Syntax error            | Fix syntax, not behavior         |
| Wrote implementation    | Delete it, return to test        |
| Multiple tests at once  | Pick ONE                         |

#### 6.2 GREEN - Minimal Implementation

**Iron Law:** ONLY WRITE CODE THE TEST REQUIRES

1. Write minimal code to pass test
2. Run test → verify passes
3. Run FULL test suite → verify no regressions
4. Commit: `feat: [scenario name]`

**Verification Gate:** Evidence before claims.

| Claim            | Requires                      | Not Sufficient              |
| ---------------- | ----------------------------- | --------------------------- |
| "Tests pass"     | Fresh test output: 0 failures | "should pass", previous run |
| "Build succeeds" | Build command: exit 0         | "linter passed"             |

#### 6.3 REFACTOR - Clean Up

**Iron Law:** TESTS MUST PASS BEFORE AND AFTER EVERY CHANGE

| Smell                     | Action                           |
| ------------------------- | -------------------------------- |
| Duplication introduced    | Extract shared function/constant |
| Unclear name              | Rename to reveal intent          |
| Long function (>20 lines) | Extract helper                   |
| Magic number/string       | Extract constant                 |
| No obvious improvements   | Skip refactor, proceed to 6.4    |

**Protocol:**

1. Run tests → must pass (baseline)
2. Make ONE refactoring change
3. Run tests → must still pass
4. Commit: `refactor: [what improved]`
5. Repeat if more smells exist

**Revert if tests fail:**

```bash
git checkout -- <changed-files>
```

Then try a smaller change or skip refactoring.

#### 6.4 Mark & Iterate

1. Mark scenario `[x]` in test-definitions
2. Return to 6.1 for next scenario, or proceed to Phase 7 if all done

---

## Phase 7: Done Gate

**Entry:** All scenarios marked `[x]` in test-definitions

**Before marking ticket `status: done`, complete this checklist:**

### Required (run /done to automate)

- [ ] All scenarios `[x]` in test-definitions
- [ ] Full test suite passes
- [ ] Build succeeds
- [ ] Lint passes

### Parent Epic (if applicable)

If ticket has `parent:` field:

1. Add completion entry to parent's work log
2. If all `children:` done → update parent `status: done`

### Final Commit

1. Update ticket: `phase: done`, `status: done`, `last_modified: [now]`
2. Commit: `feat(scope): [summary]`

---

## Current Behavior

1. Detect work level (see SAFEWORD.md "Work Level Detection")
2. Announce with override hint
3. **If ticket exists:** Read phase, resume at appropriate point
4. **Phase 0-2:** Context check (goal/scope), optional discovery
5. **Phase 3:** Draft scenarios from spec, save to test-definitions
6. **Phase 4:** Validate scenarios (atomic, observable, deterministic)
7. **Phase 5:** Decompose into components, assign test layers, create task breakdown
8. **Phase 6:** TDD implementation (RED → GREEN → REFACTOR for each scenario)
9. **Phase 7:** Done gate checklist, parent epic update, final commit
10. **Update phase** in ticket when transitioning

---

## Key Takeaways

- **patch/task** → TDD directly (RED → GREEN → REFACTOR)
- **feature** → full BDD flow (Phases 0-7), track in ticket `phase:` field
- **Resume** → read ticket, find first unchecked scenario, continue
- **Split** → check thresholds at Entry, Phase 3, Phase 5; user decides
- **Done gate** → run /done before marking ticket complete
- When unsure → default to task, user can `/bdd` to override
